{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting familiar with spark - parsing YARN logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports and spark config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a pyspark instance\n",
    "import pyspark\n",
    "import pyspark.sql\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "conf = pyspark.SparkConf().setMaster(\"local[*]\").setAll([\n",
    "                                   ('spark.executor.memory', '12g'),  # find\n",
    "                                   ('spark.driver.memory','4g'), # your\n",
    "                                   ('spark.driver.maxResultSize', '2G') # setup\n",
    "                                  ])\n",
    "# create the session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# create the context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# FIX for Spark 2.x\n",
    "locale = sc._jvm.java.util.Locale\n",
    "locale.setDefault(locale.forLanguageTag(\"en-US\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading the data - parsing the YARN ressource manager log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema we want\n",
    "\n",
    "* The application's id\n",
    "* The user name\n",
    "* The number of attempts made to run the app\n",
    "* For each application's attempt,\n",
    "    * The start time. We consider the start time to be when the appattempt state changes to LAUNCHED.\n",
    "    * The end time. We consider the end time to be when the state of the appattempt changes from FINAL_SAVING to FINISHING/FAILED/KILLED.\n",
    "    * The final status of the attempt defined by the state the appattempt transitioned to from FINAL_SAVING.\n",
    "    * The list of containers requested and where they are hosted, sorted by container id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file \n",
    "log_txt = sc.textFile(\"hadoop-yarn-resourcemanager-iccluster040.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We deconstruct the parsing of the data into four distinct parts, we try to get the info we want from different lines of the logs so we will obtain three RDDs as such. \n",
    "\n",
    "* First RDD\n",
    "| ApplicationID | AttemptID | Starttime | Endtime | Final state | Number of attempts |\n",
    "|---------------|-----------|-----------|---------|-------------|--------------------|\n",
    "|               |           |           |         |             |                    |\n",
    "* Second RDD\n",
    "| ApplicationID | User |\n",
    "|---------------|------|\n",
    "|               |      |\n",
    "* Third RDD \n",
    "| ApplicationID | AttemptID | ContainerID | Host name |\n",
    "|---------------|-----------|-------------|-----------|\n",
    "|               |           |             |           |\n",
    "\n",
    "We then join all those RDDs into a single one\n",
    "\n",
    "| ApplicationID | User | Number of attempts | Attempt Number | Starttime | Finishtime | Finish State | Containers |\n",
    "|---------------|------|--------------------|----------------|-----------|------------|--------------|------------|\n",
    "|               |      |                    |                |           |            |              |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  a. Get applicationID, start time, endtime, states, number of attempts ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions for parsing\n",
    "\n",
    "def get_state(x):\n",
    "    \"\"\"\n",
    "    Change our tuple structure to extract the meaningful state from the string\n",
    "    For example we go from (LAUNCHED,LAUNCHED) to (LAUNCHED) and from (FINAL_SAVING,FINISHED) to (FINISHED)\n",
    "    Parameters:\n",
    "    x (Tuple): tuple containing app id - attempt id - and (state,state)\n",
    "    Returns:\n",
    "    x (Tuple): tuple reorganized app id - attempt id - (state)\n",
    "    \"\"\"\n",
    "    if(x[2][0].startswith('LAUNCHED') or x[2][0].startswith('FINAL_SAVING')):\n",
    "        return(x[0],x[1],x[2][1])\n",
    "    \n",
    "\n",
    "    \n",
    "# Do some processing to get the intended output\n",
    "def parse_attempt(x):\n",
    "    \"\"\"\n",
    "    Change our tuple structure to get an output like the one required for the submission\n",
    "\n",
    "    Parameters:\n",
    "    x (Tuple): tuple containing app id - attempt id - and (state,state)\n",
    "    Returns:\n",
    "    x (Tuple): tuple reorganized\n",
    "    \"\"\"\n",
    "    splitted = x[1][0].split('_')\n",
    "    splitted[0]='application'\n",
    "    return (('_'.join(splitted[:-1]),x[1][0],x[0],x[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we filter to get all the attempts from the second epochs and while studying the logfile we saw that attempts are found in lines with 'attempt.RMAppAttemptImpl'\n",
    "# We look for the states in the string, if it contains more than 1 instance of our keywords ( LAUNCHED/FINAL_SAVING/KILLED/FINISHING) we extract those states for later use\n",
    "apps = log_txt.filter(lambda x : x.find('attempt.RMAppAttemptImpl')>-1 and x.find('1580812675067')>-1)\\\n",
    "              .map(lambda x: x.split())\\\n",
    "              .map(lambda x : (x[0]+' '+x[1],[attempt for attempt in x if attempt.startswith('appattempt')],\\\n",
    "                               [state for state in x if (state.startswith('LAUNCHED') or state.startswith('FINAL_SAVING') or state.startswith('KILLED') or state.startswith('FINISHING') or state.startswith('FAILED'))]))\\\n",
    "              .filter(lambda x: len(x[2])>1 and not(x[2][1].startswith('FINAL_SAVING')))\\\n",
    "              .map(lambda x: get_state(x))\\\n",
    "              .map(lambda x: parse_attempt(x))\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We group the RDD according to its applicationid and attemptid so we could combine the start time and finish time of each attempt into a single row\n",
    "apps = apps.map(lambda x: ((x[0],x[1]), x[2:])).groupByKey().mapValues(list).map(lambda x: (x[0][0],x[0][1],x[1][0][0],x[1][1][0],x[1][1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of attempts\n",
    "# creates a dict of application id - number of attempts \n",
    "number_attempts = apps.map(lambda x: (x[0],(x[1],x[2],x[3],x[4]) )).countByKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final apps RDD with number of attempts\n",
    "apps = apps.map(lambda x: (x[0],x[1],x[2],x[3],x[4],number_attempts[x[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure of RDD obtained so far\n",
    "\n",
    "| ApplicationID | AttemptID | Starttime | Endtime | Final state | Number of attempts |\n",
    "|---------------|-----------|-----------|---------|-------------|--------------------|\n",
    "|               |           |           |         |             |                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  b. Get ApplicationID and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user with app id \n",
    "users = log_txt.filter(lambda x : x.find('capacity.ParentQueue')>-1 and x.find('1580812675067')>-1)\\\n",
    "              .map(lambda x: x.split())\\\n",
    "              .map(lambda x: (x[10],x[12]))\\\n",
    "              .distinct()\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure of RDD \n",
    "\n",
    "| ApplicationID | User |\n",
    "|---------------|------|\n",
    "|               |      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  c. Get containers linked with attemptIDs/applicationIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for parsing container info\n",
    "def parse_container(x):\n",
    "    \"\"\"\n",
    "    Change our tuple structure to get an output like the one required for the submission\n",
    "\n",
    "    Parameters:\n",
    "    x (Tuple): tuple containing some irrelevant data, waiting to get processed\n",
    "    Returns:\n",
    "    x (Tuple): tuple reorganized as such appid-attemptid-containerid-hostname\n",
    "    \"\"\"\n",
    "    splitted_container = x[0].split('_')\n",
    "    container_id = splitted_container[5]\n",
    "    splitted_container.pop(5)\n",
    "    \n",
    "    #change the way attemptid is shown so that it is the same as before\n",
    "    splitted_container[4]='0000'+splitted_container[4]\n",
    "    \n",
    "    #parse attempt id\n",
    "    attemptid = splitted_container.copy()\n",
    "    attemptid[0]='appattempt'\n",
    "    attemptid.pop(1)\n",
    "    attemptid = '_'.join(attemptid)\n",
    "    \n",
    "    #parse application id\n",
    "    applicationid = splitted_container.copy()\n",
    "    applicationid[0]='application'\n",
    "    applicationid.pop(1)\n",
    "    applicationid = '_'.join(applicationid[:-1])\n",
    "    \n",
    "    \n",
    "    splitted_host = x[1].split(':')\n",
    "    return(applicationid,attemptid,str(int(container_id)),splitted_host[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get container with attempt id \n",
    "containers = log_txt.filter(lambda x : x.find('FiCaSchedulerNode')>-1 and x.find('1580812675067')>-1)\\\n",
    "              .map(lambda x: x.split())\\\n",
    "              .map(lambda x: (x[8],x[15]))\\\n",
    "              .map(lambda x: parse_container(x))\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure of RDD\n",
    "\n",
    "| ApplicationID | AttemptID | ContainerID | Host name |\n",
    "|---------------|-----------|-------------|-----------|\n",
    "|               |           |             |           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  d. Combine the previous RDDs together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the apps RDD so that we get the applicationid as key when doing an outerjoin\n",
    "apps_zip = apps.map(lambda x: (x[0], (x[1], x[2],x[3],x[4],x[5])))\n",
    "rdd_join = apps_zip.leftOuterJoin(users)\n",
    "# we obtain an RDD that groups users and applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the containers rdd to get (applicationid,attemptid)as key and join it to the previous obtained rdd (after also performing some transformations)\n",
    "containers_zip = containers.map(lambda x: ((x[0],x[1]),(x[2],x[3])))\n",
    "rdd_join_zip = rdd_join.map(lambda x: ((x[0],x[1][0][0]),(x[1][0][1],x[1][0][2],x[1][0][3],x[1][0][4],x[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare RDD for a groupby then get the application attempts and all its containers\n",
    "joined = rdd_join_zip.leftOuterJoin(containers_zip)\\\n",
    "         .map(lambda x: ((x[0][0],x[0][1],x[1][0][0],x[1][0][1],x[1][0][2],x[1][0][3],x[1][0][4]),(x[1][1][0],x[1][1][1])))\\\n",
    "         .groupByKey().mapValues(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort according to containerid\n",
    "joined = joined.map(lambda x : (x[0],sorted(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the format of output to fit the submission criteria \n",
    "# change the attemptid to a number so that it fits the submission criteria ( we take the last 6 digits )\n",
    "joined = joined.map(lambda x : ((x[0][0],x[0][6],x[0][5]),(int(x[0][1][-6:]),x[0][2],x[0][3],x[0][4],x[1]))).groupByKey().mapValues(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Printing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter RDD so that we get applications with ids between 121 and 130 \n",
    "output = joined.filter(lambda x: int(x[0][0][-4:]) >= 121 and int(x[0][0][-4:]) <= 130).sortByKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(x):\n",
    "    \"\"\"\n",
    "    Prints information required for the submission\n",
    "    Parameters:\n",
    "    x (RDD): The RDD containing the applications info\n",
    "    \"\"\"\n",
    "    f= open(\"answers.txt\",\"a\")\n",
    "    nb_attempts = x[0][2]\n",
    "    f.write('ApplicationId : ' + x[0][0]+ '\\n\\n')\n",
    "    f.write('User : ' + x[0][1] + '\\n\\n')\n",
    "    f.write('NumAttempts  : ' + str(nb_attempts) + '\\n\\n')\n",
    "    for i in range(nb_attempts):\n",
    "        f.write('AttemptNumber : ' + str(x[1][i][0]) + '\\n\\n')\n",
    "        f.write('StartTime   : ' + x[1][i][1]+ '\\n\\n')\n",
    "        f.write('EndTime   : ' + x[1][i][2] + '\\n\\n')\n",
    "        f.write('FinalStatus  : ' + x[1][i][3] + '\\n\\n')\n",
    "        f.write('Containers  : ' + (str(x[1][i][4])[1:-1]).replace('\\'', '') + '\\n\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect and print the output to answers.txt\n",
    "text = output.collect()\n",
    "for x in text:\n",
    "    print_output(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Answering questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which user has submitted the highest number of applications? How many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all users with the count of how many application they launched\n",
    "users_app_frequency = joined.map(lambda x: ((x[0][1],x[0][0]))).distinct().countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top user \n",
    "top_user = sorted(users_app_frequency, key=users_app_frequency.get, reverse=True)[0]\n",
    "top_user_count = users_app_frequency[top_user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write answer to file. \n",
    "f= open(\"answers.txt\",\"a\")\n",
    "f.write('1. ' + top_user + ', ' + str(top_user_count) + '\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which user has the highest number of unsuccessful attempts of applications? How many? We define an unsuccessful attempt to be one with a final status which is not FINISHING (i.e., KILLED or FAILED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user with the end state of each attempt\n",
    "temp = rdd_join.map(lambda x: (x[1][1],x[1][0][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter end state of each attempt to a final status which is not FINISHING\n",
    "temp = temp.filter(lambda x: not(x[1].startswith('FINISHING') ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get users with the failed attempts count\n",
    "failed_users = temp.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top user and count\n",
    "top_user = sorted(failed_users, key=failed_users.get, reverse=True)[0]\n",
    "top_user_count = failed_users[top_user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write answer to file. \n",
    "f= open(\"answers.txt\",\"a\")\n",
    "f.write('2. ' + top_user + ', ' + str(top_user_count) + '\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the number of applications that started on the same date for each date on which at least one application started. We define application start time as the start time of its first attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dates and the number of applications for each date by counting by key ( and selecting the date as key)\n",
    "dates_freq = joined.map(lambda x: (x[1][0][1].split()[0],x[0][0])).countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dates \n",
    "dates_freq_sorted = sorted(dates_freq.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2020-02-11', 61),\n",
       " ('2020-02-13', 29),\n",
       " ('2020-02-12', 22),\n",
       " ('2020-02-10', 14),\n",
       " ('2020-02-16', 4),\n",
       " ('2020-02-04', 1)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_freq_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write answer to file. \n",
    "f= open(\"answers.txt\",\"a\")\n",
    "\n",
    "f.write('3. ')\n",
    "answer = ''\n",
    "for date in dates_freq_sorted:\n",
    "    answer+=date[0]+ ': ' + str(date[1])+', '\n",
    "f.write(answer[:-2]+'\\n\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the mean application duration (from starting the first attempt till the end of the last attempt) in ms (rounded to an integer value)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get application id with sorted attempts\n",
    "temp = joined.map(lambda x: (x[0][0],sorted(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the application id with the start of first attempt and end of last attempt\n",
    "temp = temp.map(lambda x: (x[0][0],x[1][0][1],x[1][-1][2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "# get the difference between first attempt and end of last attempt\n",
    "temp2 = temp.map(lambda x: (datetime.strptime(x[2], \"%Y-%m-%d %H:%M:%S,%f\") - datetime.strptime(x[1], \"%Y-%m-%d %H:%M:%S,%f\")).total_seconds()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write answer to file. \n",
    "f= open(\"answers.txt\",\"a\")\n",
    "f.write('4. ')\n",
    "f.write(str(int(temp2.mean())) +'\\n\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the mean duration of application attempts that completed successfully in ms (rounded to an integer value)? We define an appattempt to be successful if its final state (defined as earlier) is FINISHING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get application id with sorted attempts\n",
    "temp = joined.map(lambda x: (x[0][0],sorted(x[1])))\n",
    "\n",
    "temp = temp.filter(lambda x: x[1][-1][3].startswith('FINISHING'))\n",
    "\n",
    "# get the application id with the start of first attempt and end of last attempt\n",
    "temp = temp.map(lambda x: (x[0][0],x[1][-1][1],x[1][-1][2]))\n",
    "\n",
    "# get the difference between first attempt and end of last attempt\n",
    "temp2 = temp.map(lambda x: (datetime.strptime(x[2], \"%Y-%m-%d %H:%M:%S,%f\") - datetime.strptime(x[1], \"%Y-%m-%d %H:%M:%S,%f\")).total_seconds()*1000)\n",
    "\n",
    "# Write answer to file. \n",
    "f= open(\"answers.txt\",\"a\")\n",
    "f.write('5. ')\n",
    "f.write(str(int(temp2.mean())) +'\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many different machines have hosted containers? What are their hostnames, sorted in lexicographic order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get machines\n",
    "machines = containers.map(lambda x: x[3]).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host names of machines in lexicographic order\n",
    "machines = sorted(machines.collect(),reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of different machines in totel\n",
    "nr = len(machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write answer to file. \n",
    "f= open(\"answers.txt\",\"a\")\n",
    "f.write('6. ' + str(nr) + ', ')\n",
    "names = ''\n",
    "for host in machines:\n",
    "    names += host + ', '\n",
    "\n",
    "f.write(names[:-2]+'\\n\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which machine hosted the maximum number of applications? How many? We consider a machine to have hosted an application if it launched at least one container in any of the attempts of that application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get machines with applications\n",
    "machines_with_apps_count = containers.map(lambda x: (x[3],x[0])).distinct().countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top user and count\n",
    "top_machine = sorted(machines_with_apps_count, key=machines_with_apps_count.get, reverse=True)[0]\n",
    "top_machine_count = machines_with_apps_count[top_machine ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write answer to file. \n",
    "f= open(\"answers.txt\",\"a\")\n",
    "f.write('7. ' + top_machine + ', ' + str(top_machine_count) + '\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
